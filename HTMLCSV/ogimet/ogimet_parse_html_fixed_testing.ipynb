{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#parse single html (for testing)\n",
    "import os\n",
    "os.chdir(\"B:/Projects/CourseWork/coursework/HTMLCSV/ogimet/data\")\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(open(\"2019/22019.html\", 'rb'), \"lxml\")\n",
    "# soup = BeautifulSoup(open(\"1999/101999.html\", 'rb'), \"lxml\")\n",
    "soup = soup.select('body > table> tr:nth-child(2) > td:nth-child(2) > table:nth-child(2) > thead')[0]\n",
    "\n",
    "# get parameters\n",
    "params_list = []\n",
    "for i in (soup.select('tr:nth-child(1)')[0]).find_all('th'):\n",
    "    params_list.append(i.text)\n",
    "\n",
    "len(params_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#one row\n",
    "\n",
    "one_row = {}\n",
    "# data + time \n",
    "one_row[params_list[0]] = soup.select('tr:nth-child(2) > td:nth-child(1) > a')[0].string + ' ' + soup.select('tr:nth-child(2) > td:nth-child(2) > a')[0].string\n",
    "one_row[params_list[1]] = soup.select('tr:nth-child(2) > td:nth-child(3) > font')[0].string # T\n",
    "one_row[params_list[2]] = soup.select('tr:nth-child(2) > td:nth-child(4) > font')[0].string # Td\n",
    "one_row[params_list[3]] = soup.select('tr:nth-child(2) > td:nth-child(5)')[0].string # Tmax\n",
    "one_row[params_list[4]] = soup.select('tr:nth-child(2) > td:nth-child(6)')[0].string # Tmin\n",
    "one_row[params_list[5]] = soup.select('tr:nth-child(2) > td:nth-child(7) > font')[0].string # ddd\n",
    "one_row[params_list[6]] = soup.select('tr:nth-child(2) > td:nth-child(8) > font')[0].string # ff\n",
    "one_row[params_list[7]] = soup.select('tr:nth-child(2) > td:nth-child(9)')[0].string # gust\n",
    "one_row[params_list[8]] = soup.select('tr:nth-child(2) > td:nth-child(10) > font')[0].string # P0 hPa\n",
    "one_row[params_list[9]] = soup.select('tr:nth-child(2) > td:nth-child(11) > font')[0].string # P sea\n",
    "one_row[params_list[10]] = soup.select('tr:nth-child(2) > td:nth-child(12) > font')[0].string # P Tnd\n",
    "one_row[params_list[11]] = soup.select('tr:nth-child(2) > td:nth-child(13)')[0].string # Prec\n",
    "one_row[params_list[12]] = soup.select('tr:nth-child(2) > td:nth-child(14) > font')[0].string # Nt \n",
    "one_row[params_list[13]] = soup.select('tr:nth-child(2) > td:nth-child(15) > font')[0].string # Nh\n",
    "one_row[params_list[14]] = soup.select('tr:nth-child(2) > td:nth-child(16)')[0].string # Hkm\n",
    "one_row[params_list[15]] = soup.select('tr:nth-child(2) > td:nth-child(17)')[0].string # Inso D-1\n",
    "one_row[params_list[16]] = soup.select('tr:nth-child(2) > td:nth-child(18) > font')[0].string # Vis km\n",
    "\n",
    "# conditions\n",
    "if params_list[17] == \"WW\":\n",
    "    one_row[params_list[17]] = soup.select('tr:nth-child(2) > td:nth-child(20) > img')[0]['alt'] # WW\n",
    "else:\n",
    "    one_row[params_list[17]] = soup.select('tr:nth-child(2) > td:nth-child(19)')[0].string # Snow\n",
    "\n",
    "one_row[params_list[18]] = soup.select('tr:nth-child(2) > td:nth-child(20) > img')[0]['alt'] # WW\n",
    "one_row[params_list[19]] = soup.select('tr:nth-child(2) > td:nth-child(21) > img')[0]['alt'] # W1\n",
    "try:\n",
    "    one_row[params_list[20]] = soup.select('tr:nth-child(2) > td:nth-child(22) > img')[0]['alt'] # W2\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# print row\n",
    "for keys,values in one_row.items():\n",
    "    print(keys, end = ': ')\n",
    "    print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one month parse\n",
    "# reversed and append to dataframe\n",
    "# append to dataframe\n",
    "import pandas as pd\n",
    "data = []\n",
    "col_names = ['date', 'time', 'temp', 'temp_d', 'Tmax','Tmin','ddd', 'ff_kmh', 'Gust_kmh', 'P0_hPa', 'P_sea_hPa','P_Tnd', 'P_rec','N_t','N_h','H_Km','Inso_D_1','Vis_km','Snow', 'WW', 'W1', 'W2']\n",
    "\n",
    "soup = BeautifulSoup(open(\"2002/102002.html\", 'rb'), \"lxml\")\n",
    "soup = soup.select('body > table> tr:nth-child(2) > td:nth-child(2) > table:nth-child(2) > thead')[0]\n",
    "\n",
    "# get parameters\n",
    "params_list = []\n",
    "for i in (soup.select('tr:nth-child(1)')[0]).find_all('th'):\n",
    "    params_list.append(i.text)\n",
    "\n",
    "len(params_list)\n",
    "print(params_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as tm\n",
    "start = tm.time()\n",
    "print(\"hello\")\n",
    "end = tm.time()\n",
    "print(end - start)\n",
    "date_times = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile as profile\n",
    "\n",
    "# In outer section of code\n",
    "pr = profile.Profile()\n",
    "pr.disable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# In section you want to profile\n",
    "pr.enable()\n",
    "\n",
    "for i, tr in enumerate(reversed(soup.findAll(\"tr\"))):\n",
    "    if i == len(soup.findAll(\"tr\")) - 1:\n",
    "        continue\n",
    "    \n",
    "    date = str(tr.select('td:nth-child(1) > a')[0].string)\n",
    "    \n",
    "    time = str(tr.select('td:nth-child(2) > a')[0].string)\n",
    "    \n",
    "    temp = str(tr.select('td:nth-child(3) > font')[0].string)\n",
    "    \n",
    "    \n",
    "    temp_d = soup.select('td:nth-child(4) > font')[0].string\n",
    "    \n",
    "    Tmax = soup.select('td:nth-child(5)')[0].string\n",
    "    \n",
    "    Tmin = soup.select('td:nth-child(6)')[0].string\n",
    "    \n",
    "    ddd = soup.select('td:nth-child(7) > font')[0].string\n",
    "    \n",
    "    ff_kmh = soup.select('td:nth-child(8) > font')[0].string\n",
    "   \n",
    "    Gust_kmh = soup.select('td:nth-child(9)')[0].string\n",
    "    \n",
    "    P0_hPa = soup.select('td:nth-child(10) > font')[0].string\n",
    "    \n",
    "    P_sea_hPa = soup.select('td:nth-child(11) > font')[0].string\n",
    "    \n",
    "    P_Tnd = soup.select('td:nth-child(12) > font')[0].string\n",
    "    \n",
    "    P_rec = soup.select('td:nth-child(13)')[0].string\n",
    "    \n",
    "    N_t = soup.select('td:nth-child(14) > font')[0].string\n",
    "    \n",
    "    N_h = soup.select('td:nth-child(15) > font')[0].string\n",
    "    \n",
    "    H_Km = soup.select('td:nth-child(16) > font')[0].string\n",
    "    \n",
    "    Inso_D_1 = soup.select('td:nth-child(17)')[0].string\n",
    "    \n",
    "    Vis_km = soup.select('td:nth-child(18) > font')[0].string\n",
    "    \n",
    "    \n",
    "    Snow = None\n",
    "    WW = None\n",
    "    W1 = None\n",
    "    W2 = None\n",
    "    # condition:\n",
    "    if params_list[17] == \"WW\":\n",
    "        WW = soup.select('td:nth-child(19) > img')[0]['alt'] # WW\n",
    "        \n",
    "        W1 = soup.select('td:nth-child(20) > img')[0]['alt'] # W1\n",
    "        \n",
    "        W2 = soup.select('td:nth-child(21) > img')[0]['alt'] # W2\n",
    "        \n",
    "    elif params_list[17] == \"Snow\":\n",
    "        Snow = soup.select('td:nth-child(19)')[0].string # Snow\n",
    "        WW = soup.select('td:nth-child(20) > img')[0]['alt'] # WW\n",
    "        W1 = soup.select('td:nth-child(21) > img')[0]['alt'] # W1\n",
    "        W2 = soup.select('td:nth-child(22) > img')[0]['alt'] # W2\n",
    "    \n",
    "#     print(date, end = ' ')\n",
    "    data.append({'date': date, 'time': time, 'temp': temp, 'temp_d':temp_d, 'Tmax':Tmax, 'Tmin':Tmin, 'ddd':ddd, 'ff_kmh':ff_kmh, 'Gust_kmh':Gust_kmh, 'P0_hPa':P0_hPa, 'P_sea_hPa':P_sea_hPa, 'P_Tnd':P_Tnd, 'P_rec':P_rec, 'N_t':N_t, 'N_h':N_h, 'H_Km':H_Km, 'Inso_D_1':Inso_D_1, 'Vis_km':Vis_km, 'WW': WW, 'W1': W1, 'W2': W2})\n",
    "\n",
    "    break\n",
    "df = pd.DataFrame(data, columns = col_names)\n",
    "\n",
    "# code of interest\n",
    "pr.disable()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back in outer section of code\n",
    "pr.dump_stats('profile.pstat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in date_times:\n",
    "    print(tm.strftime('%Y-%m-%d %H:%M:%S', tm.localtime(item)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[date_time] = df[date] + ' ' df[time]\n",
    "# df = df.drop_duplicates(subset='date_time')\n",
    "df.to_csv('weather_test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('weather_test.csv', index_col=0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir(\"B:/Projects/CourseWork/coursework/HTMLCSV/ogimet/data\")\n",
    "\n",
    "df = pd.read_csv('weather_test.csv', index_col=0)\n",
    "df['date'] = pd.to_datetime(df['date'], format=\"%m/%d/%Y\")\n",
    "df['time'] = pd.to_datetime(df.time,format='%H:%M').dt.time\n",
    "\n",
    "# replace '-----' to nan\n",
    "df['T'].replace('-----', np.nan, inplace=True)\n",
    "df['Tmax'].replace('-----', np.nan, inplace=True)\n",
    "df['Tmin'].replace('-----', np.nan, inplace=True)\n",
    "\n",
    "df['T'] = df['T'].astype(float)\n",
    "df['Tmax'] = df['Tmax'].astype(float)\n",
    "df['Tmin'] = df['Tmin'].astype(float)\n",
    "\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "url = 'https://www.ogimet.com/cgi-bin/gsynres?ind=28698&lang=en&decoded=yes&ndays=30&ano=2019&mes=11&day=1'\n",
    "page = requests.get(url).text\n",
    "table = pd.read_html(page)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "url=\"https://www.ogimet.com/cgi-bin/gsynres?ind=28698&lang=en&decoded=yes&ndays=30&ano=2019&mes=11&day=1\"\n",
    "response = requests.get(url).text\n",
    "soup = BeautifulSoup(response, \"html.parser\")\n",
    "soup_results = soup.find(\"thead\").find_all(\"tr\")\n",
    "for result in soup_results[1:]:\n",
    "    out = (result.text).strip().replace('\\n', '|')\n",
    "    print (out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "url=\"https://www.ogimet.com/cgi-bin/gsynres?ind=28698&lang=en&decoded=yes&ndays=30&ano=2019&mes=11&day=1\"\n",
    "response = requests.get(url).text\n",
    "soup = BeautifulSoup(response, \"html.parser\")\n",
    "soup_results = soup.find(\"thead\").find_all(\"tr\")\n",
    "sr = str(soup_results)\n",
    "sr = sr[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# testing\n",
    "url=\"https://www.ogimet.com/cgi-bin/gsynres?ind=28698&lang=en&decoded=yes&ndays=30&ano=2019&mes=11&day=1\"\n",
    "response = requests.get(url).text\n",
    "soup = BeautifulSoup(response, \"html.parser\")\n",
    "soup_results = soup.find(\"thead\").find_all(\"tr\")\n",
    "\n",
    "row = soup_results[0].find_all(\"td\")\n",
    "row[0].text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# testing\n",
    "\n",
    "col_names = ['date', 'time', 'temp', 'temp_d', 'Tmax','Tmin','ddd', 'ff_kmh', 'Gust_kmh', 'P0_hPa', 'P_sea_hPa','P_Tnd', 'P_rec','N_t','N_h','H_Km','Inso_D_1','Vis_km','Snow', 'WW', 'W1', 'W2']\n",
    "\n",
    "data = []\n",
    "\n",
    "url=\"https://www.ogimet.com/cgi-bin/gsynres?ind=28698&lang=en&decoded=yes&ndays=30&ano=2019&mes=11&day=1\"\n",
    "response = requests.get(url).text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# testing\n",
    "\n",
    "soup = BeautifulSoup(response, \"html.parser\")\n",
    "soup_results = soup.find(\"thead\").find_all(\"tr\")\n",
    "for result in soup_results[1:]:\n",
    "    cell = result.find_all(\"td\")\n",
    "    cell[0].text\n",
    "    data.append({'date': cell[0].text, 'time': cell[1].text, 'temp': cell[2].text, 'temp_d':cell[3].text, 'Tmax':cell[4].text, 'Tmin':cell[5].text, 'ddd':cell[6].text, 'ff_kmh':cell[7].text, 'Gust_kmh':cell[8].text, 'P0_hPa':cell[9].text, 'P_sea_hPa':cell[10].text, 'P_Tnd':cell[11].text, 'P_rec':cell[12].text, 'N_t':cell[13].text, 'N_h':cell[14].text, 'H_Km':cell[15].text, 'Inso_D_1':cell[16].text, 'Vis_km':cell[17].text, 'WW': cell[19].text, 'W1': cell[20].text, 'W2': cell[21].text})\n",
    "    \n",
    "df = pd.DataFrame(data, columns = col_names)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response, \"html.parser\")\n",
    "soup_results = soup.find(\"thead\").find_all(\"th\")\n",
    "results = [result.text for result in soup_results]\n",
    "[print(item) for item in results]\n",
    "print(len(results))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11/01/2019'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "\n",
    "col_names = ['date', 'time', 'temp', 'temp_d', 'Tmax','Tmin','ddd', 'ff_kmh', 'Gust_kmh', 'P0_hPa', 'P_sea_hPa','P_Tnd', 'P_rec','N_t','N_h','H_Km','Inso_D_1','Vis_km','Snow', 'WW', 'W1', 'W2']\n",
    "\n",
    "data = []\n",
    "\n",
    "url=\"https://www.ogimet.com/cgi-bin/gsynres?ind=28698&lang=en&decoded=yes&ndays=30&ano=2019&mes=11&day=1\"\n",
    "response = requests.get(url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>temp</th>\n",
       "      <th>temp_d</th>\n",
       "      <th>Tmax</th>\n",
       "      <th>Tmin</th>\n",
       "      <th>ddd</th>\n",
       "      <th>ff_kmh</th>\n",
       "      <th>Gust_kmh</th>\n",
       "      <th>P0_hPa</th>\n",
       "      <th>...</th>\n",
       "      <th>P_rec</th>\n",
       "      <th>N_t</th>\n",
       "      <th>N_h</th>\n",
       "      <th>H_Km</th>\n",
       "      <th>Inso_D_1</th>\n",
       "      <th>Vis_km</th>\n",
       "      <th>Snow</th>\n",
       "      <th>WW</th>\n",
       "      <th>W1</th>\n",
       "      <th>W2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11/01/2019</td>\n",
       "      <td>12:00</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>-----</td>\n",
       "      <td>-----</td>\n",
       "      <td>WSW</td>\n",
       "      <td>18.0</td>\n",
       "      <td>61.2</td>\n",
       "      <td>989.9</td>\n",
       "      <td>...</td>\n",
       "      <td>----</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>---</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11/01/2019</td>\n",
       "      <td>09:00</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-5.8</td>\n",
       "      <td>-----</td>\n",
       "      <td>-----</td>\n",
       "      <td>SW</td>\n",
       "      <td>18.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>988.6</td>\n",
       "      <td>...</td>\n",
       "      <td>----</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>---</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11/01/2019</td>\n",
       "      <td>06:00</td>\n",
       "      <td>1.8</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>-----</td>\n",
       "      <td>-----</td>\n",
       "      <td>WSW</td>\n",
       "      <td>18.0</td>\n",
       "      <td>43.2</td>\n",
       "      <td>987.7</td>\n",
       "      <td>...</td>\n",
       "      <td>----</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>---</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11/01/2019</td>\n",
       "      <td>03:00</td>\n",
       "      <td>3.2</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>-----</td>\n",
       "      <td>1.1</td>\n",
       "      <td>WSW</td>\n",
       "      <td>21.6</td>\n",
       "      <td>39.6</td>\n",
       "      <td>986.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4/12h</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11/01/2019</td>\n",
       "      <td>00:00</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-----</td>\n",
       "      <td>-----</td>\n",
       "      <td>WSW</td>\n",
       "      <td>7.2</td>\n",
       "      <td>----</td>\n",
       "      <td>984.5</td>\n",
       "      <td>...</td>\n",
       "      <td>----</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>---</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   time  temp temp_d   Tmax   Tmin  ddd ff_kmh Gust_kmh P0_hPa  \\\n",
       "0  11/01/2019  12:00  -0.2   -6.4  -----  -----  WSW   18.0     61.2  989.9   \n",
       "1  11/01/2019  09:00   1.4   -5.8  -----  -----   SW   18.0     54.0  988.6   \n",
       "2  11/01/2019  06:00   1.8   -3.6  -----  -----  WSW   18.0     43.2  987.7   \n",
       "3  11/01/2019  03:00   3.2   -3.2  -----    1.1  WSW   21.6     39.6  986.0   \n",
       "4  11/01/2019  00:00   4.2    3.0  -----  -----  WSW    7.2     ----  984.5   \n",
       "\n",
       "   ...    P_rec N_t N_h H_Km Inso_D_1 Vis_km Snow WW  W1 W2  \n",
       "0  ...     ----   5   3  0.6      ---   10.0  NaN            \n",
       "1  ...     ----   8   8  0.6      ---   20.0  NaN            \n",
       "2  ...     ----   6   6  0.6      ---   20.0  NaN            \n",
       "3  ...  0.4/12h   6   6  0.6      0.0   20.0  NaN            \n",
       "4  ...     ----   8   8  0.6      ---   10.0  NaN            \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "\n",
    "soup = BeautifulSoup(response, \"html.parser\")\n",
    "soup_results = soup.find(\"thead\").find_all(\"tr\")\n",
    "for result in soup_results[1:]:\n",
    "    cell = result.find_all(\"td\")\n",
    "    cell[0].text\n",
    "    data.append({'date': cell[0].text, 'time': cell[1].text, 'temp': cell[2].text, 'temp_d':cell[3].text, 'Tmax':cell[4].text, 'Tmin':cell[5].text, 'ddd':cell[6].text, 'ff_kmh':cell[7].text, 'Gust_kmh':cell[8].text, 'P0_hPa':cell[9].text, 'P_sea_hPa':cell[10].text, 'P_Tnd':cell[11].text, 'P_rec':cell[12].text, 'N_t':cell[13].text, 'N_h':cell[14].text, 'H_Km':cell[15].text, 'Inso_D_1':cell[16].text, 'Vis_km':cell[17].text, 'WW': cell[19].text, 'W1': cell[20].text, 'W2': cell[21].text})\n",
    "    \n",
    "df = pd.DataFrame(data, columns = col_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "T(C)\n",
      "Td(C)\n",
      "Tmax(C)\n",
      "Tmin(C)\n",
      "ddd\n",
      "ffkmh\n",
      "Gustkmh\n",
      "P0hPa\n",
      "P seahPa\n",
      "PTnd\n",
      "Prec(mm)\n",
      "Nt\n",
      "Nh\n",
      "HKm\n",
      "InsoD-1\n",
      "Viskm\n",
      "Snow(cm)\n",
      "WW\n",
      "W1\n",
      "W2\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(response, \"html.parser\")\n",
    "soup_results = soup.find(\"thead\").find_all(\"th\")\n",
    "results = [result.text for result in soup_results]\n",
    "[print(item) for item in results]\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}